### 1. Базовая модель
Первоначально, базовая модель строилась на датасете с почасовыми данными, в котором было около 140 миллионов строк и более 50 признаков<br>
Базовая модель - модель линейной регрессии с поиском минимума стохастическим градиентным спуском (SGDRegressor)<br>

Так как для хранения всего датасета было недостаточно памяти, были созданы csv файлы с тренировочными и тестовыми данными<br>
Перед обучением пропуски были заполнены медианным значением по всему датасету<br>
Данные были нормализованы с помощью StandardScaler<br>

Обучение модели происходило по 20 млн строк, полное обучение занимало более 10 часов<br>
Модель показала следующие результаты:<br>
* MSE = 40.68
* $R^2$ = 0.54

### 2. Дополнительная обработка данных
Было принято решение обработать датасет:<br>
* Убрать детализацию по часам и перейти к детализации по дням. Это уменьшило датасет до 5,8 миллионов строк
* Была обучена модель линейной регрессии с L1 регуляризацией для того, чтобы убрать незначимые признаки
* Были убраны признаки с высокой мультиколлинеарностью
* Были убраны признаки с низкой корреляцией с целевой переменной

После этих преобразований мы получили датасет с 25 признаками<br>

### 3. Обучение других моделей регрессии
Перед обучением моделей необходимо обработать исходный датасет<br>
Для каждого столбца разный алгоритм обработки пропусков<br>
* Строки с пропусками в столбце european_aqi можем удалить
* Строки с глубиной снега заполняем 0, так как пропуски в июле и августе
* Строки со скоростью ветра заполняем медианным значением региона по году и месяцу
* Пропуски в поле income заполняем медианным значением по году по региону
* Пропуски в поле nitrogen_monoxide заполняем медианным значением по году и региону

Категориальные признаки кодируем с помощью LaberEncoder<br>

Обучаем модели с подбором гиперпараметров с помощью GridSearch. Также предварительно нормализуем данные с помощью StandardScaler<br>
* Linear Regression
* Elastic Net
* Decision Tree Regressor
* Random Forest REgressor
* CatBoost
* Flaml AutoML

![Alt text](https://github.com/AI-YP-24-2-1/aqi_prediction/blob/main/images/models_results.png?raw=true)

Наилучшее качество показывает модель CatBoost<br>
* MSE = 8.77
* $R^2$ = 0.87

Также, в случае AutoML CatBoost показывает следующие результаты:<br>
* MSE = 6.92
* $R^2$ = 0.9

Далее, были протестированы различные методы снижения размерности<br>
* PCA
* Isolation Forest

Для проверки эффекта обучим Decision Tree и CatBoost с лучшими гиперпараметрами и сравним результаты

![Alt text](https://github.com/AI-YP-24-2-1/aqi_prediction/blob/main/images/models_results_size.png?raw=true)

Видим, что MSE и $R^2$ стали хуже при снижении размерности с помощью PCA и Isolation Forest<br>

Получаем, что наилучшей моделью является модель CatBoost с гиперпараметрами:<br>
* n_estimators = 8192
* learning_rate = 0.1
* early_stopping_rounds = 10
