### 1. Обработка данных
Перед обучением моделей необходимо обработать исходный датасет<br>
Применяем ту же обработку данных, что и для ml обучения<br>
Для каждого столбца разный алгоритм обработки пропусков<br>
* Строки с пропусками в столбце european_aqi можем удалить
* Строки с глубиной снега заполняем 0, так как пропуски в июле и августе
* Строки со скоростью ветра заполняем медианным значением региона по году и месяцу
* Пропуски в поле income заполняем медианным значением по году по региону
* Пропуски в поле nitrogen_monoxide заполняем медианным значением по году и региону

Категориальные признаки кодируем с помощью LaberEncoder<br>
Нормализуем данные с помощью StandardScaler<br>

### 2. Обучение моделей
Для обучения моделей разделяем тренировочную выборку на тренировочную и валидационную

#### 2.1 Обучаем первую DL модель
* Кол-во нейронов 512
* Learning rate 1e-3
* batch size 32
* Кол-во эпох 20
* 2 линейных слоя
* Функция активации RELU
* Оптимизация SGD

Получаем MSE = 8.794

#### 2.2 Применяем оптимизацию Adam
* Кол-во нейронов 512
* Learning rate 1e-3
* batch size 32
* Кол-во эпох 20
* 2 линейных слоя
* Функция активации RELU
* Оптимизация Adam

Получаем MSE = 7.828<br>
Видим, что лучше использовать оптимизацию ADAM<br>
Также видим, что график прыгает, поэтому уменьшим learning rate до 1e-4

#### 2.3 Добавляем больше нейронов и больше слоев
* Кол-во нейронов 1024
* Learning rate 1e-4
* batch size 32
* Кол-во эпох 20
* 3 линейных слоя
* Функция активации RELU
* Оптимизация Adam

Получаем MSE = 2.256

#### 2.4 Добавляем Dropout
* Кол-во нейронов 1024
* Learning rate 1e-4
* batch size 32
* Кол-во эпох 20
* 3 линейных слоя
* Функция активации RELU
* Оптимизация Adam
* Dropout

Добавление Dropout увеличило MSE. MSE = 4.017

#### 2.5 Добавляем больше слоев и нейронов
Видим, что на предыдущих этапах добавление нейронов и новых слоев уменьшало MSE. Добавим больше слоев и нейронов
* Кол-во нейронов 2048
* Learning rate 1e-4
* batch size 32
* Кол-во эпох 10
* 5 линейных слоев
* Функция активации RELU
* Оптимизация Adam

Получаем MSE = 1.866<br>
Эту модель и используем как финальную модель

#### 2.6 Обучаем модель на всех данных
* Кол-во нейронов 2048
* Learning rate 1e-4
* batch size 32
* Кол-во эпох 20
* 5 линейных слоев
* Функция активации RELU
* Оптимизация Adam

Получаем MSE = 1.559

![Alt text](https://github.com/AI-YP-24-2-1/aqi_prediction/blob/main/images/11.all_models.png?raw=true)
