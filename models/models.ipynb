{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from flaml import AutoML\n",
    "from catboost import CatBoostRegressor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"{'/'.join(os.getcwd().split('/')[:3])}/year_project\"\n",
    "df = pd.read_csv(f'{file_path}/csv_data/air_weather_data_lite.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Заполняем пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого столбца разный алгоритм обработки пропусков<br>\n",
    "* Строки с пропусками в столбце european_aqi можем удалить\n",
    "* Строки с глубиной снега заполняем 0, так как пропуски в июле и августе\n",
    "* Строки со скоростью ветра заполняем медианным значением региона по году и месяцу\n",
    "* Пропуски в поле income заполняем медианным значением по году по региону\n",
    "* Пропуски в поле nitrogen_monoxide заполняем медианным значением по году и региону"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['european_aqi'], inplace=True)\n",
    "df['snow_depth'] = df['snow_depth'].fillna(0)\n",
    "\n",
    "wind_median = df.groupby(['region', 'year', 'month'])['snow_depth'].transform('median')\n",
    "df['wind_speed_10m'] = df['snow_depth'].fillna(wind_median)\n",
    "\n",
    "median_income_by_region_year = df.groupby(['region', 'year'])['income'].median().reset_index().rename(columns={'income': 'median_income'})\n",
    "df = df.merge(median_income_by_region_year, on=['region', 'year'], how='left')\n",
    "df['income'] = df['income'].fillna(df['median_income'])\n",
    "df = df.drop(columns=['median_income'])\n",
    "\n",
    "median_monoxide_by_region_year = df.groupby(['region', 'year'])['nitrogen_monoxide'].median().reset_index().rename(columns={'nitrogen_monoxide': 'nitrogen_monoxide_median'})\n",
    "df = df.merge(median_monoxide_by_region_year, on=['region', 'year'], how='left')\n",
    "df['nitrogen_monoxide'] = df['nitrogen_monoxide'].fillna(df['nitrogen_monoxide_median'])\n",
    "df = df.drop(columns=['nitrogen_monoxide_median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Разделение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['european_aqi', 'city_id'], axis=1)\n",
    "y = df['european_aqi']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "del df, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем категориальные признаки с помощью LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модели с подбором гиперпараметров с помощью GridSearch. Также предварительно нормализуем данные с помощью StandardScaler<br>\n",
    "* Linear Regression\n",
    "* Elastic Net\n",
    "* Decision Tree Regressor\n",
    "* Random Forest REgressor\n",
    "* CatBoost\n",
    "* Flaml AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_prefix(params):\n",
    "    stripped_params = {}\n",
    "    for key, value in params.items():\n",
    "        stripped_key = key.split('__')[-1] if '__' in key else key\n",
    "        stripped_params[stripped_key] = value\n",
    "    return stripped_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 22.65991389373462\n",
      "R^2 Score: 0.6612416002027388\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('Linear_Regression', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results.append({\n",
    "        \"Model\": 'Linear Regression',\n",
    "        'MSE': mse,\n",
    "        \"R^2\": r2,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем к модели линейной регрессии регуляризацию, обучаем Elastic Net и подбираем гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'elasticnet__alpha': 0.001, 'elasticnet__l1_ratio': 1.0}\n",
      "Mean Squared Error: 22.660028813282782\n",
      "R^2 Score: 0.6612398821925811\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('elasticnet', ElasticNet())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'elasticnet__alpha': [0.001, 0.01, 0.1],\n",
    "    'elasticnet__l1_ratio': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results.append({\n",
    "        \"Model\": 'Elastic Net',\n",
    "        'MSE': mse,\n",
    "        \"R^2\": r2,\n",
    "        **strip_prefix(grid_search.best_params_)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регуляризация не повлияла на улучшение качества прогноза"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'Decision Tree Regressor__ccp_alpha': 0.01, 'Decision Tree Regressor__max_depth': 30, 'Decision Tree Regressor__max_leaf_nodes': 100}\n",
      "Mean Squared Error: 14.298053009706729\n",
      "R^2 Score: 0.7862487218398522\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('Decision Tree Regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'Decision Tree Regressor__max_depth': [30, 50, 70],\n",
    "    'Decision Tree Regressor__max_leaf_nodes': [50, 70, 100],\n",
    "    'Decision Tree Regressor__ccp_alpha': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results.append({\n",
    "        \"Model\": 'Decision Tree Regressor',\n",
    "        'MSE': mse,\n",
    "        \"R^2\": r2,\n",
    "        **strip_prefix(grid_search.best_params_)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'Random Forest Regressor__ccp_alpha': 0.01, 'Random Forest Regressor__max_depth': 30, 'Random Forest Regressor__max_leaf_nodes': 100, 'Random Forest Regressor__n_estimators': 40}\n",
      "Mean Squared Error: 14.081758018637208\n",
      "R^2 Score: 0.789482262152604\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('Random Forest Regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'Random Forest Regressor__n_estimators': [20, 40],\n",
    "    'Random Forest Regressor__max_depth': [30, 50],\n",
    "    'Random Forest Regressor__max_leaf_nodes': [50, 70, 100],\n",
    "    'Random Forest Regressor__ccp_alpha': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results.append({\n",
    "        \"Model\": 'Random Forest Regressor',\n",
    "        'MSE': mse,\n",
    "        \"R^2\": r2,\n",
    "        **strip_prefix(grid_search.best_params_)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'CatBoost Regressor__depth': 8, 'CatBoost Regressor__iterations': 200, 'CatBoost Regressor__l2_leaf_reg': 3, 'CatBoost Regressor__learning_rate': 0.1}\n",
      "Mean Squared Error: 8.76949668326902\n",
      "R^2 Score: 0.8688988547183756\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('CatBoost Regressor', CatBoostRegressor(random_state=42, verbose=0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'CatBoost Regressor__iterations': [100, 200],\n",
    "    'CatBoost Regressor__learning_rate': [0.01, 0.1],\n",
    "    'CatBoost Regressor__depth': [6, 8],\n",
    "    'CatBoost Regressor__l2_leaf_reg': [3, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline, \n",
    "    param_grid=param_grid, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": 'CatBoost Regressor',\n",
    "    'MSE': mse,\n",
    "    \"R^2\": r2,\n",
    "    **strip_prefix(grid_search.best_params_)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Flaml AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 03-17 12:16:55] {1728} INFO - task = regression\n",
      "[flaml.automl.logger: 03-17 12:16:55] {1739} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 03-17 12:17:02] {1838} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 03-17 12:17:02] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'catboost']\n",
      "[flaml.automl.logger: 03-17 12:17:02] {2258} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:02] {2393} INFO - Estimated sufficient time budget=1487592s. Estimated necessary time budget=2618s.\n",
      "[flaml.automl.logger: 03-17 12:17:02] {2442} INFO -  at 81.9s,\testimator lgbm's best error=42.7241,\tbest estimator lgbm's best error=42.7241\n",
      "[flaml.automl.logger: 03-17 12:17:02] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:03] {2442} INFO -  at 82.2s,\testimator lgbm's best error=42.7241,\tbest estimator lgbm's best error=42.7241\n",
      "[flaml.automl.logger: 03-17 12:17:03] {2258} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:03] {2442} INFO -  at 82.5s,\testimator lgbm's best error=24.6136,\tbest estimator lgbm's best error=24.6136\n",
      "[flaml.automl.logger: 03-17 12:17:03] {2258} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:03] {2442} INFO -  at 82.7s,\testimator lgbm's best error=16.6510,\tbest estimator lgbm's best error=16.6510\n",
      "[flaml.automl.logger: 03-17 12:17:03] {2258} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:03] {2442} INFO -  at 83.0s,\testimator lgbm's best error=16.6510,\tbest estimator lgbm's best error=16.6510\n",
      "[flaml.automl.logger: 03-17 12:17:03] {2258} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:04] {2442} INFO -  at 83.3s,\testimator lgbm's best error=16.6510,\tbest estimator lgbm's best error=16.6510\n",
      "[flaml.automl.logger: 03-17 12:17:04] {2258} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:04] {2442} INFO -  at 83.5s,\testimator lgbm's best error=16.2747,\tbest estimator lgbm's best error=16.2747\n",
      "[flaml.automl.logger: 03-17 12:17:04] {2258} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:17:04] {2442} INFO -  at 83.8s,\testimator xgboost's best error=42.8979,\tbest estimator lgbm's best error=16.2747\n",
      "[flaml.automl.logger: 03-17 12:17:04] {2258} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2442} INFO -  at 84.1s,\testimator lgbm's best error=16.2747,\tbest estimator lgbm's best error=16.2747\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2258} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2442} INFO -  at 84.3s,\testimator xgboost's best error=42.8979,\tbest estimator lgbm's best error=16.2747\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2258} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2442} INFO -  at 84.7s,\testimator lgbm's best error=15.1158,\tbest estimator lgbm's best error=15.1158\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2258} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2442} INFO -  at 84.8s,\testimator xgboost's best error=25.5556,\tbest estimator lgbm's best error=15.1158\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2258} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2442} INFO -  at 85.0s,\testimator xgboost's best error=18.5095,\tbest estimator lgbm's best error=15.1158\n",
      "[flaml.automl.logger: 03-17 12:17:05] {2258} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:17:06] {2442} INFO -  at 85.1s,\testimator xgboost's best error=18.5095,\tbest estimator lgbm's best error=15.1158\n",
      "[flaml.automl.logger: 03-17 12:17:06] {2258} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:06] {2442} INFO -  at 85.4s,\testimator lgbm's best error=15.1158,\tbest estimator lgbm's best error=15.1158\n",
      "[flaml.automl.logger: 03-17 12:17:06] {2258} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:17:06] {2442} INFO -  at 85.5s,\testimator xgboost's best error=18.4288,\tbest estimator lgbm's best error=15.1158\n",
      "[flaml.automl.logger: 03-17 12:17:06] {2258} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:08] {2442} INFO -  at 87.7s,\testimator lgbm's best error=13.3607,\tbest estimator lgbm's best error=13.3607\n",
      "[flaml.automl.logger: 03-17 12:17:08] {2258} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:11] {2442} INFO -  at 90.5s,\testimator lgbm's best error=13.3607,\tbest estimator lgbm's best error=13.3607\n",
      "[flaml.automl.logger: 03-17 12:17:11] {2258} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:12] {2442} INFO -  at 91.8s,\testimator lgbm's best error=13.3607,\tbest estimator lgbm's best error=13.3607\n",
      "[flaml.automl.logger: 03-17 12:17:12] {2258} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:14] {2442} INFO -  at 93.3s,\testimator lgbm's best error=13.3607,\tbest estimator lgbm's best error=13.3607\n",
      "[flaml.automl.logger: 03-17 12:17:14] {2258} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:17:16] {2442} INFO -  at 95.6s,\testimator lgbm's best error=13.3607,\tbest estimator lgbm's best error=13.3607\n",
      "[flaml.automl.logger: 03-17 12:17:16] {2258} INFO - iteration 21, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:17:17] {2442} INFO -  at 96.4s,\testimator catboost's best error=14.1938,\tbest estimator lgbm's best error=13.3607\n",
      "[flaml.automl.logger: 03-17 12:17:17] {2258} INFO - iteration 22, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:17:29] {2442} INFO -  at 108.1s,\testimator catboost's best error=14.1938,\tbest estimator lgbm's best error=13.3607\n",
      "[flaml.automl.logger: 03-17 12:17:29] {2258} INFO - iteration 23, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:17:33] {2442} INFO -  at 112.6s,\testimator catboost's best error=12.3203,\tbest estimator catboost's best error=12.3203\n",
      "[flaml.automl.logger: 03-17 12:17:33] {2258} INFO - iteration 24, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:17:55] {2442} INFO -  at 134.6s,\testimator catboost's best error=12.3203,\tbest estimator catboost's best error=12.3203\n",
      "[flaml.automl.logger: 03-17 12:17:55] {2258} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:18:02] {2442} INFO -  at 141.2s,\testimator lgbm's best error=13.3607,\tbest estimator catboost's best error=12.3203\n",
      "[flaml.automl.logger: 03-17 12:18:02] {2258} INFO - iteration 26, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:18:14] {2442} INFO -  at 153.3s,\testimator catboost's best error=9.2131,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:18:14] {2258} INFO - iteration 27, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:18:38] {2442} INFO -  at 177.4s,\testimator catboost's best error=9.2131,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:18:38] {2258} INFO - iteration 28, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:18:42] {2442} INFO -  at 181.8s,\testimator catboost's best error=9.2131,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:18:42] {2258} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:18:48] {2442} INFO -  at 188.0s,\testimator lgbm's best error=11.0074,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:18:48] {2258} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:18:51] {2442} INFO -  at 190.6s,\testimator lgbm's best error=10.3254,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:18:51] {2258} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:18:53] {2442} INFO -  at 192.5s,\testimator lgbm's best error=10.3254,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:18:53] {2258} INFO - iteration 32, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:19:10] {2442} INFO -  at 209.8s,\testimator catboost's best error=9.2131,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:19:10] {2258} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:19:12] {2442} INFO -  at 211.3s,\testimator lgbm's best error=10.3254,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:19:12] {2258} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 12:19:22] {2442} INFO -  at 221.7s,\testimator lgbm's best error=10.2423,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:19:22] {2258} INFO - iteration 35, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:19:26] {2442} INFO -  at 225.3s,\testimator catboost's best error=9.2131,\tbest estimator catboost's best error=9.2131\n",
      "[flaml.automl.logger: 03-17 12:19:26] {2258} INFO - iteration 36, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:20:16] {2442} INFO -  at 275.3s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:20:16] {2258} INFO - iteration 37, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:21:05] {2442} INFO -  at 324.5s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:21:05] {2258} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:21:05] {2442} INFO -  at 324.6s,\testimator xgboost's best error=17.7475,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:21:05] {2258} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:21:05] {2442} INFO -  at 324.7s,\testimator xgboost's best error=17.7475,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:21:05] {2258} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:21:05] {2442} INFO -  at 325.0s,\testimator xgboost's best error=16.1294,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:21:05] {2258} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 12:21:06] {2442} INFO -  at 325.3s,\testimator xgboost's best error=16.1268,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:21:06] {2258} INFO - iteration 42, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:21:13] {2442} INFO -  at 332.0s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:21:13] {2258} INFO - iteration 43, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:21:30] {2442} INFO -  at 349.4s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:21:30] {2258} INFO - iteration 44, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:26:19] {2442} INFO -  at 638.7s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:26:19] {2258} INFO - iteration 45, current learner catboost\n",
      "[flaml.automl.logger: 03-17 12:30:07] {2442} INFO -  at 866.5s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 12:30:07] {2258} INFO - iteration 46, current learner catboost\n",
      "[flaml.automl.logger: 03-17 13:00:42] {2442} INFO -  at 2701.4s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:00:42] {2258} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 13:00:49] {2442} INFO -  at 2708.6s,\testimator lgbm's best error=10.2423,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:00:49] {2258} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 03-17 13:00:49] {2442} INFO -  at 2708.7s,\testimator xgboost's best error=16.1268,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:00:49] {2258} INFO - iteration 49, current learner catboost\n",
      "[flaml.automl.logger: 03-17 13:02:45] {2442} INFO -  at 2824.0s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:02:45] {2258} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 13:02:50] {2442} INFO -  at 2829.5s,\testimator lgbm's best error=10.2423,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:02:50] {2258} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 13:02:55] {2442} INFO -  at 2834.5s,\testimator lgbm's best error=10.2423,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:02:55] {2258} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 13:03:02] {2442} INFO -  at 2841.5s,\testimator lgbm's best error=10.2423,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:03:02] {2258} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 03-17 13:03:06] {2442} INFO -  at 2845.7s,\testimator lgbm's best error=10.2423,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:03:06] {2258} INFO - iteration 54, current learner catboost\n",
      "[flaml.automl.logger: 03-17 13:31:34] {2442} INFO -  at 4553.7s,\testimator catboost's best error=7.0803,\tbest estimator catboost's best error=7.0803\n",
      "[flaml.automl.logger: 03-17 13:39:23] {2685} INFO - retrain catboost for 468.5s\n",
      "[flaml.automl.logger: 03-17 13:39:23] {2688} INFO - retrained model: <catboost.core.CatBoostRegressor object at 0x135b61640>\n",
      "[flaml.automl.logger: 03-17 13:39:23] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 03-17 13:39:23] {1986} INFO - Time taken to find the best model: 275.3252112865448\n",
      "Mean Squared Error: 6.921256847647129\n",
      "R^2 Score: 0.8965294437882635\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "\n",
    "automl.fit(\n",
    "    X_train, y_train,\n",
    "    task='regression',\n",
    "    time_budget=3600,\n",
    "    metric='mse',\n",
    "    estimator_list=['lgbm', 'xgboost', 'catboost'],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": f'Flaml AutoML: {automl.model.__class__.__name__}',\n",
    "    'MSE': mse,\n",
    "    \"R^2\": r2,\n",
    "    **strip_prefix(automl.best_config)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R^2</th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>ccp_alpha</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>depth</th>\n",
       "      <th>iterations</th>\n",
       "      <th>l2_leaf_reg</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>early_stopping_rounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>22.659914</td>\n",
       "      <td>0.661242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>22.660029</td>\n",
       "      <td>0.661240</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>14.298053</td>\n",
       "      <td>0.786249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>14.081758</td>\n",
       "      <td>0.789482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost Regressor</td>\n",
       "      <td>8.769497</td>\n",
       "      <td>0.868899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flaml AutoML: CatBoostEstimator</td>\n",
       "      <td>6.921257</td>\n",
       "      <td>0.896529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model        MSE       R^2  alpha  l1_ratio  \\\n",
       "0                Linear Regression  22.659914  0.661242    NaN       NaN   \n",
       "1                      Elastic Net  22.660029  0.661240  0.001       1.0   \n",
       "2          Decision Tree Regressor  14.298053  0.786249    NaN       NaN   \n",
       "3          Random Forest Regressor  14.081758  0.789482    NaN       NaN   \n",
       "4               CatBoost Regressor   8.769497  0.868899    NaN       NaN   \n",
       "5  Flaml AutoML: CatBoostEstimator   6.921257  0.896529    NaN       NaN   \n",
       "\n",
       "   ccp_alpha  max_depth  max_leaf_nodes  n_estimators  depth  iterations  \\\n",
       "0        NaN        NaN             NaN           NaN    NaN         NaN   \n",
       "1        NaN        NaN             NaN           NaN    NaN         NaN   \n",
       "2       0.01       30.0           100.0           NaN    NaN         NaN   \n",
       "3       0.01       30.0           100.0          40.0    NaN         NaN   \n",
       "4        NaN        NaN             NaN           NaN    8.0       200.0   \n",
       "5        NaN        NaN             NaN        8192.0    NaN         NaN   \n",
       "\n",
       "   l2_leaf_reg  learning_rate  early_stopping_rounds  \n",
       "0          NaN            NaN                    NaN  \n",
       "1          NaN            NaN                    NaN  \n",
       "2          NaN            NaN                    NaN  \n",
       "3          NaN            NaN                    NaN  \n",
       "4          3.0            0.1                    NaN  \n",
       "5          NaN            0.1                   10.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее качество показывает модель CatBoost<br>\n",
    "* MSE = 8.77\n",
    "* $R^2$ = 0.87\n",
    "\n",
    "Также, в случае AutoML CatBoost показывает следующие результаты:<br>\n",
    "* MSE = 6.92\n",
    "* $R^2$ = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Снижение размерности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем различные методы снижения размерности<br>\n",
    "Для проверки эффекта обучим Decision Tree и CatBoost с лучшими гиперпараметрами и сравним результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_size = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Метод главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_anomalies(X_train, y_train):\n",
    "    pca = PCA(n_components=2)\n",
    "    df_pca = pca.fit_transform(X_train)\n",
    "    distances = np.sqrt(np.sum(df_pca**2, axis=1))\n",
    "    threshold = np.mean(distances) + 3 * np.std(distances)\n",
    "    mask = distances <= threshold\n",
    "    X_train_filtered = X_train[mask]\n",
    "    y_train_filtered = y_train[mask]\n",
    "    return X_train_filtered, y_train_filtered\n",
    "\n",
    "X_train_filtered, y_train_filtered = remove_anomalies(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 14.594433565237694\n",
      "R^2 Score: 0.7818179281839923\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('DecisionTree', DecisionTreeRegressor(random_state=42, ccp_alpha=0.01, max_depth=30, max_leaf_nodes=100))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_filtered, y_train_filtered)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results_size.append({\n",
    "        \"Model\": 'Decision Tree Regressor',\n",
    "        'MSE PCA': mse,\n",
    "        \"R^2 PCA\": r2\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 9.159054502123622\n",
      "R^2 Score: 0.8630750910464322\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('DecisionTree', CatBoostRegressor(random_state=42, verbose=0, depth=8, iterations=200, l2_leaf_reg=3, learning_rate=0.1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_filtered, y_train_filtered)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results_size.append({\n",
    "    \"Model\": 'CatBoost Regressor',\n",
    "    'MSE PCA': mse,\n",
    "    \"R^2 PCA\": r2\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_anomalies(X_train, y_train):\n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "    predictions = iso_forest.fit_predict(X_train)\n",
    "    mask = predictions != -1\n",
    "    X_train_filtered = X_train[mask]\n",
    "    y_train_filtered = y_train[mask]\n",
    "    return X_train_filtered, y_train_filtered\n",
    "\n",
    "X_train_filtered, y_train_filtered = remove_anomalies(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 14.911119222934635\n",
      "R^2 Score: 0.777083579803709\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('DecisionTree', DecisionTreeRegressor(random_state=42, ccp_alpha=0.01, max_depth=30, max_leaf_nodes=100))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_filtered, y_train_filtered)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results_size.append({\n",
    "        \"Model\": 'Decision Tree Regressor',\n",
    "        'MSE Isolation Forest': mse,\n",
    "        \"R^2 Isolation Forest\": r2\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 10.628415828055488\n",
      "R^2 Score: 0.8411086134229542\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('DecisionTree', CatBoostRegressor(random_state=42, verbose=0, depth=8, iterations=200, l2_leaf_reg=3, learning_rate=0.1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_filtered, y_train_filtered)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "results_size.append({\n",
    "    \"Model\": 'CatBoost Regressor',\n",
    "    'MSE Isolation Forest': mse,\n",
    "    \"R^2 Isolation Forest\": r2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MSE PCA</th>\n",
       "      <th>MSE Isolation Forest</th>\n",
       "      <th>R^2</th>\n",
       "      <th>R^2 PCA</th>\n",
       "      <th>R^2 Isolation Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost Regressor</td>\n",
       "      <td>8.769497</td>\n",
       "      <td>9.159055</td>\n",
       "      <td>10.628416</td>\n",
       "      <td>0.868899</td>\n",
       "      <td>0.863075</td>\n",
       "      <td>0.841109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>14.298053</td>\n",
       "      <td>14.594434</td>\n",
       "      <td>14.911119</td>\n",
       "      <td>0.786249</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.777084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model        MSE    MSE PCA  MSE Isolation Forest  \\\n",
       "0       CatBoost Regressor   8.769497   9.159055             10.628416   \n",
       "1  Decision Tree Regressor  14.298053  14.594434             14.911119   \n",
       "\n",
       "        R^2   R^2 PCA  R^2 Isolation Forest  \n",
       "0  0.868899  0.863075              0.841109  \n",
       "1  0.786249  0.781818              0.777084  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_size = pd.DataFrame(results_size)\n",
    "results_size = results_size.groupby('Model', as_index=False).first()\n",
    "\n",
    "for index, row in results.iterrows():\n",
    "    results_size.loc[results_size['Model'] == row['Model'], ['MSE', 'R^2']] = [row['MSE'], row['R^2']]\n",
    "\n",
    "new_column_order = [\n",
    "    'Model',\n",
    "    'MSE', 'MSE PCA', 'MSE Isolation Forest',\n",
    "    'R^2', 'R^2 PCA', 'R^2 Isolation Forest'\n",
    "]\n",
    "\n",
    "results_size = results_size[new_column_order]\n",
    "results_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что MSE и $R^2$ стали хуже при снижении размерности с помощью PCA и Isolation Forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
